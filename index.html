<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Photo → Video (no QR) — Local</title>

  <!-- Tailwind CDN (for quick prototyping) -->
  <script src="https://cdn.tailwindcss.com"></script>

  <!-- OpenCV.js CDN (runtimes) -->
  <!-- You can replace with a local copy if you want offline -->
  <script async src="https://docs.opencv.org/4.x/opencv.js" type="text/javascript"></script>

  <style>
    /* small polish */
    html,body,#app { height: 100%; }
    /* hide debug canvases */
    .hidden-cv { display:none; visibility:hidden; width:0; height:0; }
  </style>
</head>

<body class="bg-slate-50 text-slate-900">
  <div id="app" class="min-h-screen flex flex-col items-center justify-center p-6">
    <div class="w-full max-w-3xl">
      <header class="flex items-center justify-between mb-6">
        <h1 class="text-2xl font-semibold">LivePhotoLink (local)</h1>
        <div class="text-sm text-slate-600">Scan a photo — watch its video</div>
      </header>

      <main class="bg-white rounded-2xl shadow p-6">
        <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
          <div>
            <div class="mb-3 text-sm text-slate-600">Preview camera</div>
            <div class="relative rounded-lg overflow-hidden border border-slate-200">
              <video id="camera" autoplay playsinline class="w-full h-72 object-cover bg-black"></video>
              <div id="scanOverlay" class="absolute inset-0 pointer-events-none flex items-end justify-center p-3">
                <div id="status" class="bg-white/80 text-slate-800 text-sm rounded-full px-3 py-1 backdrop-blur">Initializing...</div>
              </div>
            </div>

            <div class="mt-3 flex gap-2">
              <button id="startBtn" class="px-4 py-2 bg-emerald-500 text-white rounded shadow hover:brightness-95">Start Scan</button>
              <button id="stopBtn" class="px-4 py-2 bg-slate-200 text-slate-800 rounded hidden">Stop</button>
              <button id="testBtn" class="px-4 py-2 ml-auto bg-indigo-500 text-white rounded">Test Snap</button>
            </div>

            <div class="mt-4 text-xs text-slate-500">
              Tip: For best results, make the photo fill the camera frame, keep it fairly flat and well-lit. Printed photos and digital screens both work if the image is clear.
            </div>
          </div>

          <div>
            <div class="mb-3 text-sm text-slate-600">Your mapped photos</div>
            <div id="gallery" class="grid grid-cols-2 gap-3">
              <!-- preview thumbnails populated by JS -->
            </div>

            <div class="mt-4 text-sm text-slate-500">
              Place reference images and videos inside <code class="bg-slate-100 px-1 rounded">/assets/</code> and edit <code class="bg-slate-100 px-1 rounded">data.json</code>.
            </div>
          </div>
        </div>
      </main>

      <footer class="mt-6 text-xs text-slate-500 text-center">
        Local demo • No uploads • OpenCV.js matching (template-search multi-scale)
      </footer>
    </div>
  </div>

  <!-- Hidden canvases for opencv processing -->
  <canvas id="frameCanvas" class="hidden-cv"></canvas>
  <canvas id="refCanvas" class="hidden-cv"></canvas>

  <!-- Fullscreen modal for video -->
  <div id="videoModal" class="fixed inset-0 hidden items-center justify-center bg-black/70 z-50">
    <div class="bg-black rounded-lg shadow-lg w-full max-w-3xl">
      <div class="flex justify-end p-2">
        <button id="closeModal" class="text-white px-3 py-1">Close ✕</button>
      </div>
      <video id="playVideo" controls autoplay playsinline class="w-full rounded-b-lg"></video>
    </div>
  </div>

<script>
/*
  LivePhotoLink (frontend-only)
  - Uses OpenCV.js matchTemplate at multiple scales for quick small-scale photo matching.
  - Works best when scanned photo has similar orientation & scale as a stored reference.
  - Keep reference images moderate size (max width ~800px) for performance on mobile.
*/

const DATA_JSON = 'data.json';
const ASSETS_PATH = 'assets/'; // where images & videos live

// UI elements
const cameraEl = document.getElementById('camera');
const startBtn = document.getElementById('startBtn');
const stopBtn = document.getElementById('stopBtn');
const testBtn = document.getElementById('testBtn');
const statusEl = document.getElementById('status');
const galleryEl = document.getElementById('gallery');
const videoModal = document.getElementById('videoModal');
const playVideo = document.getElementById('playVideo');
const closeModal = document.getElementById('closeModal');

let stream = null;
let scanning = false;
let opencvReady = false;
let references = []; // {meta, matGray}

const frameCanvas = document.getElementById('frameCanvas');
const refCanvas = document.getElementById('refCanvas');

function setStatus(text) {
  statusEl.textContent = text;
}

// wait for OpenCV to be ready
function waitForOpenCV() {
  return new Promise((resolve) => {
    if (typeof cv !== 'undefined' && cv && cv['onRuntimeInitialized']) {
      cv['onRuntimeInitialized'] = () => {
        opencvReady = true;
        resolve();
      };
    } else {
      // fallback if cv already initialized
      const check = () => {
        if (window.cv && cv.Mat) {
          opencvReady = true;
          resolve();
        } else {
          setTimeout(check, 100);
        }
      };
      check();
    }
  });
}

// preload data.json and create grayscale mats for references
async function loadReferences() {
  setStatus('Loading map...');
  const resp = await fetch(DATA_JSON);
  const arr = await resp.json();

  references = [];
  galleryEl.innerHTML = '';

  const loadImage = (src) => new Promise((res, rej) => {
    const img = new Image();
    img.crossOrigin = 'anonymous';
    img.onload = () => res(img);
    img.onerror = rej;
    img.src = src;
  });

  for (let item of arr) {
    const imagePath = ASSETS_PATH + item.image;
    const videoPath = ASSETS_PATH + item.video;

    // add gallery thumbnail
    const thumb = document.createElement('div');
    thumb.className = 'rounded overflow-hidden border p-1 bg-white';
    thumb.innerHTML = `
      <img src="${imagePath}" alt="${item.label||item.image}" class="w-full h-24 object-cover"/>
      <div class="mt-1 text-xs text-slate-600">${item.label || item.image}</div>
    `;
    galleryEl.appendChild(thumb);

    try {
      const img = await loadImage(imagePath);

      // convert to cv.Mat (gray) scaled to a reasonable size
      const maxRefWidth = 600; // tune for memory/speed
      const scale = Math.min(1, maxRefWidth / img.width);
      const w = Math.round(img.width * scale);
      const h = Math.round(img.height * scale);

      refCanvas.width = w;
      refCanvas.height = h;
      const rctx = refCanvas.getContext('2d');
      rctx.clearRect(0,0,w,h);
      rctx.drawImage(img, 0, 0, w, h);

      let src = cv.imread(refCanvas);
      let gray = new cv.Mat();
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
      src.delete();

      references.push({
        meta: item,
        matGray: gray,
        width: w,
        height: h
      });

    } catch (e) {
      console.error('Failed loading reference', imagePath, e);
    }
  }

  setStatus('Ready — press "Start Scan"');
}

// Start camera
async function startCamera() {
  if (scanning) return;
  try {
    stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' }, audio: false });
    cameraEl.srcObject = stream;
    await cameraEl.play();
    scanning = true;
    startBtn.classList.add('hidden');
    stopBtn.classList.remove('hidden');
    setStatus('Scanning…');
    requestAnimationFrame(scanLoop);
  } catch (e) {
    console.error(e);
    setStatus('Camera access denied or not available.');
  }
}

function stopCamera() {
  if (!scanning) return;
  scanning = false;
  if (stream) {
    for (const t of stream.getTracks()) t.stop();
  }
  cameraEl.pause();
  cameraEl.srcObject = null;
  startBtn.classList.remove('hidden');
  stopBtn.classList.add('hidden');
  setStatus('Stopped');
}

// perform match: template match at multiple scales
function matchFrameWithRefs(frameGrayMat) {
  // For each reference, try matchTemplate on various scales
  for (let ref of references) {
    // compute how many scales to try based on ratio
    // reference small → scale up frame or scale reference down; here we scale reference.
    const scales = [1.0, 0.9, 0.8, 1.1]; // some scale candidates
    for (let s of scales) {
      // scale ref mat by s into tmpRef
      let tmpRef = new cv.Mat();
      if (s === 1.0) {
        tmpRef = ref.matGray.clone();
      } else {
        const newW = Math.max(8, Math.round(ref.width * s));
        const newH = Math.max(8, Math.round(ref.height * s));
        cv.resize(ref.matGray, tmpRef, new cv.Size(newW, newH), 0, 0, cv.INTER_AREA);
      }

      // if frame smaller than template skip
      if (frameGrayMat.cols < tmpRef.cols || frameGrayMat.rows < tmpRef.rows) {
        tmpRef.delete();
        continue;
      }

      // result size
      const resultCols = frameGrayMat.cols - tmpRef.cols + 1;
      const resultRows = frameGrayMat.rows - tmpRef.rows + 1;
      const result = new cv.Mat();
      cv.matchTemplate(frameGrayMat, tmpRef, result, cv.TM_CCOEFF_NORMED);
      const mm = cv.minMaxLoc(result);
      const maxVal = mm.maxVal;

      result.delete();
      tmpRef.delete();

      // debug threshold — tune as needed; 0.65 is permissive
      if (maxVal >= 0.67) {
        console.log('MATCH!', ref.meta.image, 'score=', maxVal);
        return { match: true, meta: ref.meta, score: maxVal };
      }
    }
  }
  return { match: false };
}

// main scan loop: grabs frame, makes gray mat, calls matcher
let lastScanTime = 0;
const SCAN_INTERVAL = 400; // ms between frames to analyze

async function scanLoop(timestamp) {
  if (!scanning) return;

  if (!cameraEl.videoWidth || !cameraEl.videoHeight) {
    requestAnimationFrame(scanLoop);
    return;
  }

  if (timestamp - lastScanTime >= SCAN_INTERVAL) {
    lastScanTime = timestamp;

    // draw video frame to canvas scaled
    const maxW = 900; // scale down feed for speed
    const aspect = cameraEl.videoWidth / cameraEl.videoHeight;
    const w = Math.min(maxW, cameraEl.videoWidth);
    const h = Math.round(w / aspect);

    frameCanvas.width = w;
    frameCanvas.height = h;
    const fctx = frameCanvas.getContext('2d');
    fctx.drawImage(cameraEl, 0, 0, w, h);

    // read into OpenCV mat
    let src = cv.imread(frameCanvas);
    let gray = new cv.Mat();
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
    src.delete();

    // attempt to match
    const result = matchFrameWithRefs(gray);

    gray.delete();

    if (result.match) {
      // stop camera and play video
      setStatus('Matched: ' + (result.meta.label || result.meta.image));
      stopCamera();
      playLinkedVideo(result.meta.video);
      return;
    } else {
      setStatus('Scanning…');
    }
  }

  requestAnimationFrame(scanLoop);
}

// open video modal and play
function playLinkedVideo(filename) {
  const url = ASSETS_PATH + filename;
  playVideo.src = url;
  playVideo.currentTime = 0;
  videoModal.classList.remove('hidden');
  videoModal.style.display = 'flex';
  // autoplay is set; some browsers require user gesture for sound. that's OK.
}

// close modal
closeModal.addEventListener('click', () => {
  playVideo.pause();
  playVideo.src = '';
  videoModal.classList.add('hidden');
  videoModal.style.display = 'none';
  setStatus('Ready — press "Start Scan"');
});

// Test button: snapshot & run 1 match attempt (good for debugging)
testBtn.addEventListener('click', async () => {
  if (!cameraEl.srcObject) {
    setStatus('Start camera first then press Test Snap.');
    return;
  }

  // draw frame
  frameCanvas.width = cameraEl.videoWidth;
  frameCanvas.height = cameraEl.videoHeight;
  const fctx = frameCanvas.getContext('2d');
  fctx.drawImage(cameraEl, 0, 0, frameCanvas.width, frameCanvas.height);

  let src = cv.imread(frameCanvas);
  let gray = new cv.Mat();
  cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
  src.delete();

  const r = matchFrameWithRefs(gray);
  gray.delete();
  if (r.match) {
    setStatus('Test match found: ' + (r.meta.label || r.meta.image) + ' (score ' + r.score.toFixed(2) + ')');
  } else {
    setStatus('No match (try repositioning or better lighting).');
  }
});

// Start/Stop UI
startBtn.addEventListener('click', startCamera);
stopBtn.addEventListener('click', stopCamera);

// init
(async function init() {
  setStatus('Loading OpenCV...');
  await waitForOpenCV();
  setStatus('OpenCV ready. Loading references...');
  await loadReferences();
})();

</script>
</body>
</html>
